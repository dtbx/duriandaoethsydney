# DaoM8

Welcome to DaoM8, a Telegram bot that helps you summarize group conversations for implementation in DAOs.

It utilizes [Libertai's decentralized LLM API](https://libertai.io/apis/text-generation/) for generating context-aware summaries
of group conversations and breaking down complex consensus into simple, digestible summaries.

It comprises two main components:
- A Telegram bot that listens to group conversations and generates summaries.
- A server that serves as a bridge between the bot and the LLM API for generating dao proposals.

## Requirements

- Python3 + virtualenv

## Usage

The bot works by acting as a moderator in a group chat, connected to a DAO. It listens to messages in the group chat and generates summaries of the conversation based on the messages it receives.
You can interact with it by creating new conversations, asking it for summaries, and pushing the end results to IPFS.

The server acts as a bridge between the bot and the LLM API. It exposes a REST API over for end users to interact with the bots state.
The purpose of the server is allow to users to browse completed transcripts, and to generate proposals based on the transcripts.

This server can be called within an oracle to mint these proposals on-chain, or just back to the user so that they can tweak the proposal before submitting it to the DAO.

By using this Tool DAOs can enable better auditability and transparency in their decision making processes, as well as benefit from the AI generated summaries, querying, organization, and proposal generation. DaoM8 is a simple tool that can be used to help DAOs make better decisions.

### Telegram Bot

See ![docs/bot.svg](docs/bot.svg) for an overview of the bot's command flow.

### Server API

The sever exposes the following API endpoints:

```
# Get all transcripts (completed and pushed conversations belonging to the DAO)
GET /api/transcripts?chat_id=<chat_id>&dao_addr=<dao_addr>

# Post a hash of a specific transcript and generate a proposal. The server will fetch the transcript from IPFS and generate a proposal using the LLM API.
#  It alse allows the user to specify the desired intent or opionion of the proposal.
POST /api/propose {
  intent: <intent>,
  ipfs_hash: <ipfs_hash>,
}

```

## Setup

### Configuration

#### Note on Environment Variables

The bot is configured using environment variables.

It is best to do this in a `.env` file at the root of this repository. Our scripts will look for this file and use it to set the environment variables.

You can override the defaults you set in your `.env` by setting the environment variables with `export` prior to running the bot.

#### Telegram Bot Token

You must a valid Telegram Bot Token in order to use this bot. You can get one by talking to
the [BotFather](https://t.me/botfather) on Telegram.

Name this variable `TG_TOKEN` within your environment.

NOTE: If you would like to use this bot in group chats, you must enable the bot to read messages in group chats when you create it.
You can do this by turning off the "Group Privacy" setting in the bot's settings on the BotFather.

#### Logging

The logging is controlled by the `LOG_PATH` environment variable. This is the path to the log file that the bot will write to.

If this is not set, the bot will default to writing logs out to stdout only.

A good default is to set this to `./data/app.log` in the `.env` file.

#### Sqlite Database

The bot uses a sqlite database to store the knowledge base of messages that it has received.

The path to the database is controlled by the `DATABASE_PATH` environment variable. This variable should point to where our sqlite database is located.

NOTE: We explicitly don't set the full url because some tasks require `sqlite+aiosqlite` to be specified as the protocol. Rather than make the user specify this, we just ask for the path to the database file. `:memory:` is a valid option for this variable.

If this is not set, the bot will default to using `:memory:` which will create an in-memory database that will be lost when the bot is stopped.

A good default is to set this to `./data/app.db` in the `.env` file.

NOTE: The server and the bot must share the same database. If you are running the bot and the server on the same machine, you can use the same database path for both. If you are running the bot and the server on different machines, you must ensure that the database is accessible to both machines.

### Ipfs Configuration

The bot uses IPFS to store the transcripts of group conversations as well as the proposals generated by the LLM API.

The default IPFS for all of the components is `http://localhost:5001`. If you are running IPFS on a different port or on a different machine, you must set the `IPFS_HOST` environment variable to the correct IPFS host. You can also set the `IPFS_PORT` environment variable to the correct port.

Because of a weird bug in the ipfs-api client, we also need to rely on gateways to fetch the data. You can set the `IPFS_GATEWAY` environment variable to the correct gateway in your `.env` file. This is set to `http://localhost:8080` by default.

This is only relevant for the server, wheras the bot will always use the IPFS host and port.

#### Debug Mode

If you want to run the bot in debug mode, you can set the `DEBUG` environment variable to `True`.

This will log debug events related to message handling. This is very useful when developming new features.

#### Agent

The bot uses an AI agent to generate responses to user queries.

See `./agent.yaml` for the default configuration. The bot will load this file and use it to configure the agent when it starts.

If you want to change the agent configuration, you can do so by editing this file or setting the `AGENT_CONFIG_PATH` environment variable to the path of the file you want to use. This file must contain a valid yaml configuration for the agent.

See `./agent.yaml` for the default configuration and documentation on the available options.

## Installation

This command sets up a virtual environment and installs the required dependencies within it for the bot to run.

```
./scripts/install.sh
```

If you would like to run the bot please ensure you use the virtual environment created by the install script.

```
source venv/bin/activate
python3 src/bot.py
```

The same goes for running the server.
```bash
source venv/bin/activate
python3 src/server.py
```

You can tail the log file to see the logs in real time.
```
# for the telegram bot
tail -f ./data/app.bot.log
# for the server
tal -f ./data/app.server.log
```

## Usage

### Development

We provide a script to run the bot in development mode. This will run the bot in debug mode, against an in-memory database and write logs to stdout.

```
./scripts/dev_bot.sh
```

All you have to do is make sure you have a valid Telegram Bot Token set in your environment as `TG_TOKEN`.

After you have launched the bot, you can search for it on Telegram using its username and start a conversation with it.

Note, there is also a script to run the server in development mode. This will run the server in debug mode, against an in-memory database and write logs to stdout.
```
```bash
./scripts/dev_server.sh
```
However, running the two services in parallel will not ensure e2e functionality, as the server and the bot must share the same database.

### Production-ish

#### Note on Database Migrations

The bot uses an sqlite database to store the knowledge base of messages that it has received.

You can use the `alembic` tool to manage the database schema. We provide scripts for doing so within the virtual environment.

You can run the following command to generate new migrations if you have made changes to the database schema:

```
./scripts/prepare_migrations.sh
```

This will generate a new migration file in the `./alembic/versions` directory.

Include these updated migrations in your pull request when (and only when) you make changes to the database schemas.

NOTE: This script is also controlled by the `DATABASE_PATH` environment variable. If you do not set this, the script will default to using `./data/app.db` as the database path.

You can run the following command to apply the migrations to the database:

```
./scripts/migrate.sh
```

This will apply any new migrations to the database.

Like the previous script, this script is also controlled by the `DATABASE_PATH` environment variable. If you do not set this, the script will default to using `./data/app.db` as the database path.

NOTE: the bot does not run migrations automatically. You must remember to responsibly run the `migrate.sh` script when you have new migrations to apply.

#### Running the Bot

We provide a script to run the bot in production mode. This will deactivate debug mode, and allow you to configure the logging and database path. If neither of these are set, the bot will default to writing logs to `./data/app.bot.log` and using `/./data/app.db` as the database path.

```
./scripts/run_bot.sh
```
#### Running the Server

We provide a script to run the server in production mode. This will deactivate debug mode, and allow you to configure the logging and database path. If neither of these are set, the server will default to writing logs to `./data/app.server.log` and using `/./data/app.db` as the database path.

```bash
./scripts/run_server.sh
```

#### Congratulations

You now have an up and running bot that can generate summaries of group conversations.

NOTE: once again, it is your responsibility to set the `TG_TOKEN` environment variable and to run the `migrate.sh` script when you have new migrations to apply.
